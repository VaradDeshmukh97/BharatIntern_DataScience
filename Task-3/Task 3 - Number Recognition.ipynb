{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "637d8384",
   "metadata": {},
   "source": [
    "# Task 3 - Number Recognition\n",
    "\n",
    "*Varad Deshmukh*\n",
    "\n",
    "**Instructions** : Handwritten digit recognition system detects scanned images of handwritten digits. Handwritten digit recognition using MNIST dataset is a major project made with the help of Neural Network. It basically detects the scanned images of handwritten digits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9575a23c",
   "metadata": {},
   "source": [
    "> ## The MNIST Dataset\n",
    "\n",
    "The Modified National Institute of Standards and Technology (MNIST) dataset is widely used in deep learning for handwritten digits classification projects. It has 70,000 samples of handwritten digits, used to train the neural network.\n",
    "\n",
    "We built a deep neural network on the MNIST dataset using `keras`. Specifically, we create a Multilayer Perceptron, meaning a fully connected network, wherein each neuron in one layer is connected to all neurons in the next layer. To train and validate the neural network, the MNIST dataset is used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49cc3221",
   "metadata": {},
   "source": [
    "> ## Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fff9b895",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-29 12:01:48.192013: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# import necessary libraries and modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.utils import to_categorical, plot_model\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656c42c6",
   "metadata": {},
   "source": [
    "> ## Loading the dataset\n",
    "\n",
    "For loading the MNIST dataset, we use the API provided within `keras` to download and extract the images and labels automatically. Once the data is loaded, we count the number of labels for the training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e33768cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 36s 3us/step\n"
     ]
    }
   ],
   "source": [
    "# import the dataset and load it\n",
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e70dcfb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train labels :  {0: 5923, 1: 6742, 2: 5958, 3: 6131, 4: 5842, 5: 5421, 6: 5918, 7: 6265, 8: 5851, 9: 5949}\n"
     ]
    }
   ],
   "source": [
    "# count the number of unique train labels\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "print('Train labels : ', dict(zip(unique, counts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a0557d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test labels :  {0: 980, 1: 1135, 2: 1032, 3: 1010, 4: 982, 5: 892, 6: 958, 7: 1028, 8: 974, 9: 1009}\n"
     ]
    }
   ],
   "source": [
    "# count the number of unique train labels\n",
    "unique, counts = np.unique(y_test, return_counts=True)\n",
    "print('Test labels : ', dict(zip(unique, counts)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718c2078",
   "metadata": {},
   "source": [
    "> ## Data Visualisation\n",
    "\n",
    "We select 10 random samples from the MNIST dataset and visualise them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d88fc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample 10 mnist digits from the training dataset\n",
    "indexes = np.random.randint(0, X_train.shape[0], size=10)\n",
    "images = X_train[indexes]\n",
    "labels = y_train[indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa450d3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x200 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the 10 sample mnist digits\n",
    "plt.figure(figsize=(5, 2))\n",
    "for i in range(len(indexes)):\n",
    "    plt.subplot(5, 2, i+1)\n",
    "    image = images[i]\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff47074f",
   "metadata": {},
   "source": [
    "> ## Building the Multilayer Perceptron using `keras`\n",
    "\n",
    "We move forward to build the model. First we have to import the `keras` layers, which we have already done. Then we compute the number of labels, since the data should be in a correct shape and format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f1ede15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the number of labels\n",
    "num_labels = len(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0dfe6e",
   "metadata": {},
   "source": [
    "> ## One-Hot Encoding\n",
    "\n",
    "The labels for the digits in the dataset are in the form of digits, 0 to 9. For feeding these labels into the neural network to train the model, we need to encode these, just as we do with the categorical variables. We employ the One-Hot Enncoding technique for the purpose, using the `to_categorical()` utility in `keras`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a7399daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encoding\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8737d9fc",
   "metadata": {},
   "source": [
    "> ## Data Preprocessing\n",
    "\n",
    "We now compute the dimensions of the images and scale and normalize the pixel value which runs from 0 to 255 into 0 to 1. This makes training easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e098438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#image dimensions\n",
    "image_size = X_train.shape[1]\n",
    "input_size = image_size * image_size\n",
    "input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "93d26083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resizing and normalizing\n",
    "X_train = np.reshape(X_train, [-1, input_size])\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = np.reshape(X_test, [-1, input_size])\n",
    "X_test = X_test.astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dab3027",
   "metadata": {},
   "source": [
    "> ## Network Architecture\n",
    "\n",
    "We now set the network parameters, i.e the batch size, number of hidden units and the dropout rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0a261962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# network parameters\n",
    "batch_size = 128\n",
    "hidden_units = 256\n",
    "dropout = 0.45"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24455e05",
   "metadata": {},
   "source": [
    "We now design the model architecture. It will have three layers. We use the `Sequential()` class in `keras` to create the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d022e6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# designing the model\n",
    "model = Sequential()\n",
    "model.add(Dense(hidden_units, input_dim=input_size))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(dropout))\n",
    "model.add(Dense(hidden_units))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(dropout))\n",
    "model.add(Dense(num_labels))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09447f61",
   "metadata": {},
   "source": [
    "Now, we view the model summary using the `summary()` method of `keras`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2a343a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 256)               200960    \n",
      "                                                                 \n",
      " activation (Activation)     (None, 256)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               65792     \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 256)               0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                2570      \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 10)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 269322 (1.03 MB)\n",
      "Trainable params: 269322 (1.03 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed4a34d",
   "metadata": {},
   "source": [
    "> ## Implementing the model\n",
    "\n",
    "It is a three-step process :\n",
    "1. Compiling the model using `compile()` method\n",
    "2. Training the model using `fit()` method\n",
    "3. Evaluating the model performance using `evaluate()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "76f20bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7e01add9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "469/469 [==============================] - 5s 9ms/step - loss: 5.6436 - accuracy: 0.5606\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 5s 10ms/step - loss: 1.1915 - accuracy: 0.6736\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 1.0022 - accuracy: 0.7265\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.8566 - accuracy: 0.7733\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 4s 10ms/step - loss: 0.7088 - accuracy: 0.8164\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 5s 10ms/step - loss: 0.6100 - accuracy: 0.8448\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.5328 - accuracy: 0.8629\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.4708 - accuracy: 0.8773\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.4336 - accuracy: 0.8874\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.4123 - accuracy: 0.8941\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.3836 - accuracy: 0.9019\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 5s 10ms/step - loss: 0.3588 - accuracy: 0.9075\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 5s 10ms/step - loss: 0.3409 - accuracy: 0.9108\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.3306 - accuracy: 0.9153\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 6s 13ms/step - loss: 0.3228 - accuracy: 0.9171\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 5s 10ms/step - loss: 0.3121 - accuracy: 0.9203\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.3090 - accuracy: 0.9211\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.2970 - accuracy: 0.9242\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 5s 11ms/step - loss: 0.2938 - accuracy: 0.9251\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 5s 10ms/step - loss: 0.2910 - accuracy: 0.9261\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x135728390>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b6fb3cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 1s 5ms/step - loss: 0.1761 - accuracy: 0.9571\n",
      "The model test accuracy : 95.7%\n"
     ]
    }
   ],
   "source": [
    "# evaluate model performance\n",
    "loss, acc = model.evaluate(X_test, y_test, batch_size=batch_size)\n",
    "print('The model test accuracy : %.1f%%' % (100.0 * acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8f5794",
   "metadata": {},
   "source": [
    "Thus, we get a test accuracy of 95.7%, which is extremely good, especially considering the small number of epochs that we run."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
